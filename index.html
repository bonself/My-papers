<!doctype html public "-//W3C//DTD HTML 4.0 Transitional//EN">
<html>
<head>
<title>index</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta http-equiv="imagetoolbar" content="no">
<meta http-equiv="imagetoolbar" content="false">
<meta name="generator" content="LMSOFT Web Creator Pro, Version:4.0.0.4 service pack 1">
<link href="./DropBorder.css" rel="stylesheet" type="text/css">
<link href="./DropFrame.css" rel="stylesheet" type="text/css">
<link href="./BigDropFrame.css" rel="stylesheet" type="text/css">
</head>


<script type="text/javascript" src="./lmpres70.js"></script><noscript><br></noscript>

<body onresize=PosPage(2,5,1.000000,1.000000); bgcolor="#dabb74" >
<DIV STYLE="position:absolute; visibility:hidden; left:0; top:0; width:0; height:0;">
[<a href='https://github.com/bonself/Go-aboard/raw/master/papers/1%20A%20coordinated%20docking%20approach%20based%20on%20embedded%20vision.pdf'>https://github.com/bonself/Go-aboard/raw/master/papers/1%20A%20coordinated%20docking%20approach%20based%20on%20embedded%20vision.pdf</a>]<br>
[<a href='https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/2%20Embedded%20Vision%20Based%20Docking%20Approach%20for%20The%20Child%20Robot.pdf'>https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/2%20Embedded%20Vision%20Based%20Docking%20Approach%20for%20The%20Child%20Robot.pdf</a>]<br>
[<a href='https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/3%20A%20Docking%20Approach%20for%20Child%20Robot%20Based%20on%20Vision%20Guiding%20By%20Mother%20Robot.pdf'>https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/3%20A%20Docking%20Approach%20for%20Child%20Robot%20Based%20on%20Vision%20Guiding%20By%20Mother%20Robot.pdf</a>]<br>
[<a href='https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/4%20The%20Design%20of%20a%20Mother%20Robot%20for%20Marsupial%20Robotic%20System.pdf'>https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/4%20The%20Design%20of%20a%20Mother%20Robot%20for%20Marsupial%20Robotic%20System.pdf</a>]<br>
[<a href='https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/5%20A%20Visual%20Servoing%20Docking%20Approach%20for%20Marsupial%20Robotic%20System.pdf'>https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/5%20A%20Visual%20Servoing%20Docking%20Approach%20for%20Marsupial%20Robotic%20System.pdf</a>]<br>
[<a href='https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/6%20The%20Goalkeeper%20Strategy%20of%20RoboCup%20MSL%20Based%20on%20Dual%20Image%20Source..pdf'>https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/6%20The%20Goalkeeper%20Strategy%20of%20RoboCup%20MSL%20Based%20on%20Dual%20Image%20Source..pdf</a>]<br>
[<a href='https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/7%20The%20Design%20of%20a%20Indoor%20Guide%20Robot%20Based%20on%20Embedded%20Control%20System(final%20Paper).pdf'>https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/7%20The%20Design%20of%20a%20Indoor%20Guide%20Robot%20Based%20on%20Embedded%20Control%20System(final%20Paper).pdf</a>]<br>
[<a href='https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/8%20A%20monocular%20vision%20based%20method%20for%20measuring%20pose%20of%20the%20warehouse%20robot%20and%20rebuilding%20contour%20of%20the%20dome%20.pdf'>https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/8%20A%20monocular%20vision%20based%20method%20for%20measuring%20pose%20of%20the%20warehouse%20robot%20and%20rebuilding%20contour%20of%20the%20dome%20.pdf</a>]<br>
[<a href='https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/CO1%20Tracking%20Control%20for%20A%20Biomimetic%20Robotic%20Fish%20Guided%20by%20Active%20Vision.pdf'>https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/CO1%20Tracking%20Control%20for%20A%20Biomimetic%20Robotic%20Fish%20Guided%20by%20Active%20Vision.pdf</a>]<br>
[<a href='https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/CO2%20A%20New%20Monocular%20Vision%20Measurement%20Method%20to%20Estimate%203D%20Positions%20of%20Objects%20on%20Floor.pdf'>https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/CO2%20A%20New%20Monocular%20Vision%20Measurement%20Method%20to%20Estimate%203D%20Positions%20of%20Objects%20on%20Floor.pdf</a>]<br>
[<a href='https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/CO3%20Bezier%20Curve%20Based%20Path%20Planning%20for%20A%20Mobile%20Manipulator%20in%20Unknown%20Environments.pdf'>https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/CO3%20Bezier%20Curve%20Based%20Path%20Planning%20for%20A%20Mobile%20Manipulator%20in%20Unknown%20Environments.pdf</a>]<br>
[<a href='https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/CO4%20Autonomous%20Grasp%20of%20the%20Embedded%20Mobile%20Manipulator%20with%20an%20Eye-in-hand%20Camera.pdf'>https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/CO4%20Autonomous%20Grasp%20of%20the%20Embedded%20Mobile%20Manipulator%20with%20an%20Eye-in-hand%20Camera.pdf</a>]<br>
[<a href='https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/CO5%20An%20object%20grasping%20method%20based%20on%20fuzzy%20approaching%20for%20a%20mobile%20manipulator.pdf'>https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/CO5%20An%20object%20grasping%20method%20based%20on%20fuzzy%20approaching%20for%20a%20mobile%20manipulator.pdf</a>]<br>
[<a href='https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/CO6%20The%20Identifier-based%20Relative%20Position%20Estimation%20for%20Leader-follower%20Robotic%20System.pdf'>https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/CO6%20The%20Identifier-based%20Relative%20Position%20Estimation%20for%20Leader-follower%20Robotic%20System.pdf</a>]<br>
[<a href='https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/CO7%20An%20object%20recognition%20approach%20based%20on%20structural%20feature%20for%20cluttered%20indoor%20scene.pdf'>https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/CO7%20An%20object%20recognition%20approach%20based%20on%20structural%20feature%20for%20cluttered%20indoor%20scene.pdf</a>]<br>
[<a href='https://bonself.github.io/My-Basic-info'>https://bonself.github.io/My-Basic-info</a>]<br>
[<a href='https://bonself.github.io/My-rewards'>https://bonself.github.io/My-rewards</a>]<br>
[<a href='https://bonself.github.io/My-rewards'>https://bonself.github.io/My-rewards</a>]<br>
[<a href='https://bonself.github.io/My-papers'>https://bonself.github.io/My-papers</a>]<br>
[<a href='https://bonself.github.io/My-Basic-info'>https://bonself.github.io/My-Basic-info</a>]<br>
[<a href='https://bonself.github.io/My-rewards'>https://bonself.github.io/My-rewards</a>]<br>
[<a href='https://bonself.github.io/My-rewards'>https://bonself.github.io/My-rewards</a>]<br>
[<a href='https://bonself.github.io/My-papers'>https://bonself.github.io/My-papers</a>]<br>
[<a href='http://www.lmsoft.com/'>Web Creator</a>]
[<a href='http://www.lmsoft.com/'>LMSOFT</a>]
</DIV>



</DIV>
<DIV id=Text15 style="visibility:visible;position:absolute;z-index:3;left:557;top:2;">
<a name=#anchor_Text15></a>
<div class=DropFrame><div><div><div><div><div><div><div><div><div style="visibility:inherit;position:relative;left:10;top:10;width:169;height:64;">
<DIV id=LMTxtText15 style="visibility:inherit;position:relative;left:8;top:8;width:134;height:26;overflow:auto;overflowX:hidden;overflowY:auto">
<font face='Arial'>  <div align="left"><A href='https://bonself.github.io/My-Basic-info' onmouseover=LMTextBrOver('Text15',1) onmousedown=LMTextBrDown('Text15',1) onmouseup=LMTextBrUp('Text15',1) onmouseout=LMTextBrOut('Text15',1) STYLE='cursor:pointer'><font face="Arial" color="#0000ff" size="5"><span style=" font-size:18pt"><u>Basic Info</u></span></font></a></div>  </font>
</DIV>
</div></div></div></div></div></div></div></div></div></div>
</DIV>
<DIV id=Text16 style="visibility:visible;position:absolute;z-index:4;left:561;top:71;">
<a name=#anchor_Text16></a>
<div class=DropBorder><div><div><div><div><div><div><div><div><div style="visibility:inherit;position:relative;left:6;top:6;width:167;height:56;">
<DIV id=LMTxtText16 style="visibility:inherit;position:relative;left:8;top:8;width:140;height:26;">
<font face='Arial'>  <div align="left"><A href='https://bonself.github.io/My-rewards' onmouseover=LMTextBrOver('Text16',1) onmousedown=LMTextBrDown('Text16',1) onmouseup=LMTextBrUp('Text16',1) onmouseout=LMTextBrOut('Text16',1) STYLE='cursor:pointer'><font face="Arial" color="#0000ff" size="4"><span style=" font-size:16pt"><u>My </u></span></font><font   face="Times New Roman" color="#0000ff" size="4"><span style=" font-size:16pt"><u>Prototypes</u></span></font></a></div>  </font>
</DIV>
</div></div></div></div></div></div></div></div></div></div>
</DIV>
<DIV id=Text17 style="visibility:visible;position:absolute;z-index:5;left:737;top:70;">
<a name=#anchor_Text17></a>
<div class=DropBorder><div><div><div><div><div><div><div><div><div style="visibility:inherit;position:relative;left:6;top:6;width:171;height:56;">
<DIV id=LMTxtText17 style="visibility:inherit;position:relative;left:8;top:8;width:144;height:26;">
<font face='Arial'>  <div align="left"><A href='https://bonself.github.io/My-rewards' onmouseover=LMTextBrOver('Text17',1) onmousedown=LMTextBrDown('Text17',1) onmouseup=LMTextBrUp('Text17',1) onmouseout=LMTextBrOut('Text17',1) STYLE='cursor:pointer'><font face="Arial" color="#0000ff" size="4"><span style=" font-size:16pt"><u>My Rewards</u></span></font></a></div>  </font>
</DIV>
</div></div></div></div></div></div></div></div></div></div>
</DIV>

<DIV id=Text19 style="visibility:visible;position:absolute;z-index:6;left:735;top:5;">
<a name=#anchor_Text19></a>
<div class=DropBorder><div><div><div><div><div><div><div><div><div style="visibility:inherit;position:relative;left:6;top:6;width:173;height:56;">
<DIV id=LMTxtText19 style="visibility:inherit;position:relative;left:8;top:8;width:146;height:26;">
<font face='Arial'>  <div align="left"><A href='https://bonself.github.io/My-papers' onmouseover=LMTextBrOver('Text19',1) onmousedown=LMTextBrDown('Text19',1) onmouseup=LMTextBrUp('Text19',1) onmouseout=LMTextBrOut('Text19',1) STYLE='cursor:pointer'><font face="Arial" color="#0000ff" size="4"><span style=" font-size:16pt"><u>My Papers</u></span></font></a></div>  </font>
</DIV>
</div></div></div></div></div></div></div></div></div></div>
</DIV>










<DIV id=lmwcbackpanel style="visibility:visible;position:absolute;left:0;top:0;width:1000;height:6000;clip:rect(0,1000,6000,0);">
<DIV id=Page style="visibility:visible;overflow:hidden;position:absolute;z-index:1;left:0;top:0;">
<a name=#anchor_Page></a><IMG id=LMImagePage src="./lmimginv.gif" style="width:1000;height:6000;border:0;">
</DIV>
<DIV id=Text1 style="visibility:visible;position:absolute;z-index:2;left:-22;top:-9;">
<a name=#anchor_Text1></a>
<div class=BigDropFrame><div><div><div><div><div><div><div><div><div style="visibility:inherit;position:relative;left:39;top:39;width:533;height:144;">
<DIV id=LMTxtText1 style="visibility:inherit;position:relative;left:15;top:15;width:423;height:34;">
<font face='Arial'>  <div align="center"><font face="Times New Roman" size="5"><span style=" font-size:18pt"><b>CURRICULUM VITAE OF Peng Zhao</b></span></font></div>  </font>
</DIV>
</div></div></div></div></div></div></div></div></div></div>
</DIV>
<DIV id=Text3 style="visibility:visible;position:absolute;z-index:3;left:37;top:160;">
<a name=#anchor_Text3></a>
<DIV id=LMTxtText3 style="visibility:inherit;position:relative;left:15;top:15;width:770;height:446;">
<font face='Arial'>  <div align="left">&nbsp;&nbsp;</div>  </font>
</DIV>
</DIV>
<DIV id=Text7 style="visibility:visible;position:absolute;z-index:4;left:7;top:147;">
<a name=#anchor_Text7></a>
<div class=DropFrame><div><div><div><div><div><div><div><div><div style="visibility:inherit;position:relative;left:10;top:10;width:983;height:1806;">
<DIV id=LMTxtText7 style="visibility:inherit;position:relative;left:15;top:15;width:931;height:1754;overflow:auto;overflowX:hidden;overflowY:auto">
<font face='Arial'>  <div align="justify" style="margin-left:26mm; margin-right:0mm; text-indent:-26mm; margin-top:0.00mm; margin-bottom:0.00mm;"><font face="Times New Roman" size="4"><span style=" font-size:14pt"><b>Submitted Papers:</b></span></font></div>  <ol style="margin-top: 0mm; margin-bottom: 0mm; ">  <li style="margin-left: 1pt; margin-right: 0pt; padding-left: 0pt; font-family: Times New Roman;  font-size: 14pt;  color: #010101;  ">  <p align="justify"><font face="Times New Roman" size="4"><span style=" font-size:14pt; font-family:Times New Roman; color:#010101; font-weight:Bold; font-style:Normal; font-decoration:Normal"><b>Peng Zhao</b></span></font><font face="Calibri" size="4"><span style=" font-size:14pt">,</span></font><font face="Times New Roman" size="4"><span   style=" font-size:14pt"> </span></font><font face="Times New Roman"><span style=" font-size:12pt">Zhiqiang Cao, Nong Gu, Chao Zhou, De Xu, Min Tan</span></font><font face="Times New Roman" size="4"><span style=" font-size:14pt">. A Coordinated Docking Approach Based on Embedded   Vision, </span></font><A onmouseover=LMTextBrOver('Text7',1) onmousedown=LMTextBrDown('Text7',1) onmouseup=LMTextBrUp('Text7',1) onmouseout=LMTextBrOut('Text7',1) STYLE='cursor:pointer'><font face="Times New Roman" size="4"><span style=" font-size:14pt"><i>International Journal of Robotics and Automation</i></span></font></a>. 2016, 31(1):52-62. (SCI)</p>  </li>  </ol>  <p align="justify" style="margin-left:5mm; margin-right:0mm; text-indent:0mm; margin-top:0.00mm; margin-bottom:0.00mm;"><font face="Times New Roman" size="4"><span style=" font-size:14pt">&nbsp;&nbsp;&nbsp;</span></font><font face="Times New Roman"><span style=" font-size:12pt"> <b>Abstract</b>: Docking is an essential yet challenging   problem to the deployment of marsupial robotic system involving a&nbsp;&nbsp; mother robot and   severalchild robots, as the technologies such as rail-line tracking and global vision measurement are not suitable for applications in unknown   environments. This chapter presents a coordinated docking approach based on embedded vision of the child robot collaborated by the mother robot   with an innovative lifting docking station. The child robot utilizes a complementary metal oxide semiconductor (CMOS)camera to capture and extract   image features related to a benchmark attached on the docking station, and the internal correlation between its heading direction and the entry   direction of docking station is then derived, which makes the docking process be concise and convenient. On this basis, a coordinated docking task   model is built and the transition conditions among task states are presented. The precision analysis of the docking is also discussed. The experimental   results prove the effectiveness of the proposed approach. [</span></font><A href='https://github.com/bonself/Go-aboard/raw/master/papers/1%20A%20coordinated%20docking%20approach%20based%20on%20embedded%20vision.pdf' onmouseover=LMTextBrOver('Text7',2) onmousedown=LMTextBrDown('Text7',2) onmouseup=LMTextBrUp('Text7',2) onmouseout=LMTextBrOut('Text7',2) STYLE='cursor:pointer'><font face="Times New Roman" color="#0000ff" size="4"><span style=" font-size:14pt"><u>Full PDF</u></span></font></a><font face="Times New Roman"><span style=" font-size:12pt">]</span></font></p>  <p align="justify" style="margin-left:5mm; margin-right:0mm; text-indent:0mm; margin-top:0.00mm; margin-bottom:0.00mm;">&nbsp;</p>  <ol start="2" style="margin-top: 0mm; margin-bottom: 0mm; ">  <li style="margin-left: 1pt; margin-right: 0pt; padding-left: 0pt; font-family: Times New Roman;  font-size: 14pt;  color: #010101;  ">  <p align="justify"><font face="Times New Roman" size="4"><span style=" font-size:14pt; font-family:Times New Roman; color:#000000; font-weight:Bold; font-style:Normal; font-decoration:Normal"><b>Peng Zhao</b>,</span></font><font face="Times New Roman"><span style=" font-size:12pt"> Zhiqiang Cao, De X</span></font><font face="Calibri"><span   style=" font-size:12pt">,</span></font><font face="Times New Roman"><span style=" font-size:12pt"> Xuchao Chen</span></font><font face="Calibri" size="4"><span style=" font-size:14pt">.</span></font><font face="Times New Roman" size="4"><span style=" font-size:14pt"> Embedded Vision Based Docking Approach for The Child Robot,   <i>Control and Decision</i>. 2015, 30(12):2265-2269. (EI) (In Chinese)</span></font></p>  </li>  </ol>  <p align="justify" style="margin-left:5mm; margin-right:0mm; text-indent:0mm; margin-top:0.00mm; margin-bottom:0.00mm;"><font face="Times New Roman" size="4"><span style=" font-size:14pt">&nbsp;&nbsp;</span></font><font face="Times New Roman"><span style=" font-size:12pt"> <b>Abstra</b>ct: An embedded vision based docking approach   of child robot is proposed for the child robot recovery in the marsupial robotic system .   Based on the embedded vision platform, the child robot captures and processes the image data of identifier set on the entrance of the docking station,   and extracts the center of guiding identifier fast according to local color distribution features. Then, the horizontal color boundary line is fitted out with   the least square method, involving the corresponding imaging slope. By referring to the model of imaging slope-deviation angle of observation, the   child robot judges out the relationship between its heading and the normal vector of the entrance to make them basically overlap to each other and   finally finish docking. The proposed approach can achieve the accurate docking without camera calibration and its effectiveness is verified by   experiments.[</span></font><A href='https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/2%20Embedded%20Vision%20Based%20Docking%20Approach%20for%20The%20Child%20Robot.pdf' onmouseover=LMTextBrOver('Text7',3) onmousedown=LMTextBrDown('Text7',3) onmouseup=LMTextBrUp('Text7',3) onmouseout=LMTextBrOut('Text7',3) STYLE='cursor:pointer'><font face="Times New Roman" color="#0000ff" size="4"><span style=" font-size:14pt"><u>Full PDF</u></span></font></a><font face="Times New Roman"><span style=" font-size:12pt">]</span></font></p>  <p align="justify" style="margin-left:5mm; margin-right:0mm; text-indent:0mm; margin-top:0.00mm; margin-bottom:0.00mm;">&nbsp;</p>  <ol start="3" style="margin-top: 0mm; margin-bottom: 0mm; ">  <li style="margin-left: 1pt; margin-right: 0pt; padding-left: 0pt; font-family: Times New Roman;  font-size: 14pt;  color: #010101;  ">  <p align="justify"><font face="Times New Roman" size="4"><span style=" font-size:14pt; font-family:Times New Roman; color:#000000; font-weight:Bold; font-style:Normal; font-decoration:Normal"><b>Peng Zhao</b>, </span></font><font face="Times New Roman"><span style=" font-size:12pt">Zhiqiang Cao, Xuchao Chen, De Xu</span></font><font   face="Times New Roman" size="4"><span style=" font-size:14pt">. A Docking Approach for Child Robot Based on Vision Guiding By   Mother Robot. <i>Journal of Huazhong University of Science and Technology </i>(<i>Natural Science Edition</i>), 2013,   41(S1): 429-431+435. (EI) (In Chinese)</span></font></p>  </li>  </ol>  <p align="justify" style="margin-left:5mm; margin-right:0mm; text-indent:0mm; margin-top:0.00mm; margin-bottom:0.00mm;"><font face="Times New Roman" size="4"><span style=" font-size:14pt">&nbsp;&nbsp; </span></font><font face="Times New Roman"><span style=" font-size:12pt"><b>Abstra</b>ct: A docking approach for child robot suitable   for marsupial robot is designed in this paper. The mother robot obtains the posture of child   robot relative to the docking entrance by visual perception to instruct the child robot. In each of left, right and back sides of child robot, there is a   color symbol with two colors arranged vertically. The mother robot extracts the color borderline of each symbol it observed in a way of connection   growing, and then the position information of corresponding color symbol in image as well as the length ratio can be acquired to guide the motion of   child robot. Finally, the child robot enters the docking station in an appropriate posture. This approach is verified by experimental results. [</span></font><A href='https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/3%20A%20Docking%20Approach%20for%20Child%20Robot%20Based%20on%20Vision%20Guiding%20By%20Mother%20Robot.pdf' onmouseover=LMTextBrOver('Text7',4) onmousedown=LMTextBrDown('Text7',4) onmouseup=LMTextBrUp('Text7',4) onmouseout=LMTextBrOut('Text7',4) STYLE='cursor:pointer'><font face="Times New Roman" color="#0000ff" size="4"><span style=" font-size:14pt"><u>Full   PDF</u></span></font></a><font face="Times New Roman"><span style=" font-size:12pt">]</span></font></p>  <p align="justify" style="margin-left:5mm; margin-right:0mm; text-indent:0mm; margin-top:0.00mm; margin-bottom:0.00mm;">&nbsp;</p>  <ol start="4" style="margin-top: 0mm; margin-bottom: 0mm; ">  <li style="margin-left: 1pt; margin-right: 0pt; padding-left: 0pt; font-family: Times New Roman;  font-size: 14pt;  color: #010101;  ">  <p align="justify"><font face="Times New Roman" size="4"><span style=" font-size:14pt; font-family:Times New Roman; color:#010101; font-weight:Bold; font-style:Normal; font-decoration:Normal"><b>Peng Zhao</b>, </span></font><font face="Times New Roman"><span style=" font-size:12pt">Zhiqiang Cao, Lingyi Xu, Chao Zhou, De Xu</span></font><font   face="Times New Roman" size="4"><span style=" font-size:14pt">. The Design of a Mother Robot for Marsupial Robotic System,   <i>IEEE International Conference on Mechantronics and Automation</i>, 675-679, Tianjin, 2014. (EI)</span></font></p>  </li>  </ol>  <p align="justify" style="margin-left:5mm; margin-right:0mm; text-indent:0mm; margin-top:0.00mm; margin-bottom:0.00mm;"><font face="Times New Roman" size="4"><span style=" font-size:14pt">&nbsp;</span></font><font face="Times New Roman"><span style=" font-size:12pt">&nbsp; <b>Abstra</b>ct: A mother or transporting robot is designed   in this paper, which is dedicated to retrieve, transport and deploy the children or smaller   robots to configure a robotic team called the marsupial robotic system. In order to manage children robots flexibly, a multi-floor docking station is   mounted on the mother robot with a lifting platform which is dragged via lead-screw driving. Touch switches are utilized to initialize the lifting height   and identify whether a child robot arrives at the parking position. Also, a dock camera is set on the top of the station to recognize different children   robots for the purpose of deploying or retrieving. The locomotion ability is enhanced by combining the advantages of the wheeled-mobile platform   and trackedmobile platform with the concept of wheel-track combo, which barely increases the complexity of mechanism. Finally, a prototype of   mother robot is developed and implemented. [</span></font><A href='https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/4%20The%20Design%20of%20a%20Mother%20Robot%20for%20Marsupial%20Robotic%20System.pdf' onmouseover=LMTextBrOver('Text7',5) onmousedown=LMTextBrDown('Text7',5) onmouseup=LMTextBrUp('Text7',5) onmouseout=LMTextBrOut('Text7',5) STYLE='cursor:pointer'><font face="Times New Roman" color="#0000ff" size="4"><span style=" font-size:14pt"><u>Full PDF</u></span></font></a><font face="Times New Roman"><span style=" font-size:12pt">]</span></font></p>  <p align="justify" style="margin-left:5mm; margin-right:0mm; text-indent:0mm; margin-top:0.00mm; margin-bottom:0.00mm;">&nbsp;</p>  <ol start="5" style="margin-top: 0mm; margin-bottom: 0mm; ">  <li style="margin-left: 1pt; margin-right: 0pt; padding-left: 0pt; font-family: Times New Roman;  font-size: 14pt;  color: #010101;  ">  <p align="justify"><font face="Times New Roman" size="4"><span style=" font-size:14pt; font-family:Times New Roman; color:#010101; font-weight:Bold; font-style:Normal; font-decoration:Normal"><b>Peng Zhao</b>, </span></font><font face="Times New Roman"><span style=" font-size:12pt">Zhiqiang Cao, Lingyi Xu, Chao Zhou, De Xu</span></font><font   face="Calibri" size="4"><span style=" font-size:14pt">.</span></font><font face="Times New Roman" size="4"><span style=" font-size:14pt"> A Visual Servoing Docking Approach for Marsupial Robotic   System, <i>The 33rd Chinese Control Conference</i>, 8321-8325, Nanjing, 2014. (EI)</span></font></p>  </li>  </ol>  <p align="justify" style="margin-left:5mm; margin-right:0mm; text-indent:0mm; margin-top:0.00mm; margin-bottom:0.00mm;"><font face="Times New Roman" size="4"><span style=" font-size:14pt">&nbsp;&nbsp; </span></font><font face="Times New Roman"><span style=" font-size:12pt"><b>Abstra</b>ct: This paper presents a visual servoing docking   approach for marsupial robotic system. A vertical V-shaped visual benchmark is designed   to guide the docking motion of a child robot with the feedback of image features. By changing the angular of the camera with a rotational DOF, the   child robot adjusts its heading orientation for docking. The task is modeled into six states: Blind, Adistance, Atangent, Around, Aiming, and Parking   states. The transform conditions among the states are also given. To verify the approach, a simulation platform is designed, including an image-infor   virtual machine, a decision-making unit and a pose refresher. The simulation results verify the presented docking approach. [</span></font><A href='https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/5%20A%20Visual%20Servoing%20Docking%20Approach%20for%20Marsupial%20Robotic%20System.pdf' onmouseover=LMTextBrOver('Text7',6) onmousedown=LMTextBrDown('Text7',6) onmouseup=LMTextBrUp('Text7',6) onmouseout=LMTextBrOut('Text7',6) STYLE='cursor:pointer'><font face="Times New Roman" color="#0000ff" size="4"><span style=" font-size:14pt"><u>Full PDF</u></span></font></a><font face="Times New Roman"><span style=" font-size:12pt">]</span></font></p>  <p align="justify" style="margin-left:5mm; margin-right:0mm; text-indent:0mm; margin-top:0.00mm; margin-bottom:0.00mm;">&nbsp;</p>  <ol start="6" style="margin-top: 0mm; margin-bottom: 0mm; ">  <li style="margin-left: 1pt; margin-right: 0pt; padding-left: 0pt; font-family: Times New Roman;  font-size: 14pt;  color: #010101;  ">  <p align="justify"><font face="Times New Roman"><span style=" font-size:12pt; font-family:Times New Roman; color:#010101; font-weight:Normal; font-style:Normal; font-decoration:Normal">Xueyan Wang</span></font><font face="Times New Roman" size="4"><span style=" font-size:14pt">, <b>Peng Zhao, </b></span></font><font face="Times New Roman"><span   style=" font-size:12pt">et al</span></font><font face="Calibri"><span style=" font-size:12pt">.</span></font><font face="Times New Roman"><span style=" font-size:12pt"> </span></font><font face="Times New Roman" size="4"><span style=" font-size:14pt">The Goalkeeper Strategy of RoboCup MSL Based on Dual Image Source. <i>RoboCup   </i>2015<i>: Robot World Cup XIX</i></span></font><font face="����" size="4"><span style=" font-size:14pt"><i>，</i></span></font><font face="Times New Roman" size="4"><span style=" font-size:14pt">165-173<i>. Springer International Publishing</i></span></font><font face="Calibri" size="4"><span style=" font-size:14pt">.</span></font></p>  </li>  </ol>  <p align="justify" style="margin-left:5mm; margin-right:0mm; text-indent:0mm; margin-top:0.00mm; margin-bottom:0.00mm;"><font face="Calibri" size="4"><span style=" font-size:14pt">&nbsp;&nbsp; </span></font><font face="Times New Roman"><span style=" font-size:12pt"><b>Abstra</b>ct: Gatekeeping is one of the most important tasks in   MSL, especially defending aerial shots. This paper proposes a goalkeeper strategy   based on combining two image sources. The goalkeeper uses the Omni-vision system to adjust heading orientation of the Kinect sensor for capturing   both depth and RGB images of the ball. The depth information is used to detect the spatial position of the ball and the RGB image ensures the validity   of the recognition. Once opponents shoot, the proposed system uses the first few detected positions of the ball to predict the interception point by the   goalkeeper based on the least square method. The accuracy and effectiveness of the proposed strategy are verified by experimentation. [</span></font><A href='https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/6%20The%20Goalkeeper%20Strategy%20of%20RoboCup%20MSL%20Based%20on%20Dual%20Image%20Source..pdf' onmouseover=LMTextBrOver('Text7',7) onmousedown=LMTextBrDown('Text7',7) onmouseup=LMTextBrUp('Text7',7) onmouseout=LMTextBrOut('Text7',7) STYLE='cursor:pointer'><font face="Times New Roman" color="#0000ff" size="4"><span style=" font-size:14pt"><u>Full PDF</u></span></font></a><font face="Times New Roman"><span style=" font-size:12pt">]</span></font></p>  <p align="justify" style="margin-left:5mm; margin-right:0mm; text-indent:0mm; margin-top:0.00mm; margin-bottom:0.00mm;">&nbsp;</p>  <ol start="7" style="margin-top: 0mm; margin-bottom: 0mm; ">  <li style="margin-left: 1pt; margin-right: 0pt; padding-left: 0pt; font-family: Times New Roman;  font-size: 12pt;  color: #010101;  ">  <p align="justify"><font face="Times New Roman" size="4"><span style=" font-size:14pt; font-family:Times New Roman; color:#010101; font-weight:Bold; font-style:Normal; font-decoration:Normal"><b>Peng Zhao</b>, </span></font><font face="Times New Roman"><span style=" font-size:12pt">Hua Lu, Fushun Sun<i>. </i></span></font><font face="Times New Roman" size="4"><span   style=" font-size:14pt">The Design of an Indoor Guide Robot Based on Embedded Control System</span></font><font face="Times New Roman"><span style=" font-size:12pt">. <i>The 2nd   Shanghai International Symposium on Human-Centered Robotics</i>. (Accepted)</span></font></p>  </li>  </ol>  <p align="justify" style="margin-left:5mm; margin-right:0mm; text-indent:0mm; margin-top:0.00mm; margin-bottom:0.00mm;"><font face="Times New Roman" size="4"><span style=" font-size:14pt">&nbsp;&nbsp;</span></font><font face="Times New Roman"><span style=" font-size:12pt"> <b>Abstra</b>ct: A Guide Robot based on embedded electronic   System is designed in this paper. An embedded control system is proposed to integrate   modules of indoor self-localization sensors, differential driving mechanism and multimedia interaction to build the robot. The core indoor self-  localization function is achieved by fusing dead-reckoning and visual measurement involving inertial measurement unit (IMU), a pair of hall encoders   and a camera. On this basis, introducing audio files are embedded into the module of multimedia interaction, which are related with the location   coordinates. Then the robot can leads the visitor to approach the visitor sites by location coordinates and plays the multimedia files for introducing. A   prototype of the Guide Robot is developed to prove the rationality of the design with guiding and introducing service instance. [</span></font><A href='https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/7%20The%20Design%20of%20a%20Indoor%20Guide%20Robot%20Based%20on%20Embedded%20Control%20System(final%20Paper).pdf' onmouseover=LMTextBrOver('Text7',8) onmousedown=LMTextBrDown('Text7',8) onmouseup=LMTextBrUp('Text7',8) onmouseout=LMTextBrOut('Text7',8) STYLE='cursor:pointer'><font face="Times New Roman" color="#0000ff" size="4"><span style=" font-size:14pt"><u>Full PDF</u></span></font></a><font face="Times New Roman"><span style=" font-size:12pt">]</span></font></p>  <p align="justify" style="margin-left:5mm; margin-right:0mm; text-indent:0mm; margin-top:0.00mm; margin-bottom:0.00mm;">&nbsp;</p>  <ol start="8" style="margin-top: 0mm; margin-bottom: 0mm; ">  <li style="margin-left: 1pt; margin-right: 0pt; padding-left: 0pt; font-family: Times New Roman;  font-size: 14pt;  color: #010101;  ">  <p align="justify"><font face="Times New Roman" size="4"><span style=" font-size:14pt; font-family:Times New Roman; color:#010101; font-weight:Bold; font-style:Normal; font-decoration:Normal"><b>Peng Zhao</b>,</span></font><font face="Times New Roman"><span style=" font-size:12pt"> Zhiqiang Cao, Hua Lu, Shiqi Chen. </span></font><font   face="Times New Roman" size="4"><span style=" font-size:14pt">A monocular vision based method for measuring pose of the warehouse   robot and rebuilding contour of the dome. </span></font><font face="Times New Roman"><span style=" font-size:12pt"><i>The 13th China intelligent robot conference</i></span></font><font face="Calibri"><span style=" font-size:12pt"><i>.</i></span></font><font face="Times New Roman"><span style=" font-size:12pt"> (Accepted)</span></font></p>  </li>  </ol>  <p align="justify" style="margin-left:5mm; margin-right:0mm; text-indent:0mm; margin-top:0.00mm; margin-bottom:0.00mm;"><font face="Times New Roman" size="4"><span style=" font-size:14pt">&nbsp;&nbsp;</span></font><font face="Times New Roman"><span style=" font-size:12pt"> <b>Abstra</b>ct: A method for measuring pose of the warehouse   robot and rebuilding contour of the dome based on monocular vision is proposed in this   paper. Firstly， the spot array is projected onto the dome of the warehouse, and a single camera is mounted on the top of the storage robot to   observe the spots array. Secondly based on the plane movement constraint and the camera affine geometry transformation principle, the visual   measurement is exploited to measure the position of the robot and the 3d position information of the spots in the view. Between visual measurements,   dead reckoning of short distance is performed based on the data fusing of IMU and encoder odometer. Finally, the robot's real-time positioning and   sparse reconstruction of the dome shape are completed. To verify the above method, this paper designs a simulation system including information   module and data simulation module algorithm module. With simulating scenario task, the pose of the robot is calculated accurately, and the sparse   reconstruction dome outline, proving the validity of the method proposed in this paper.[</span></font><A href='https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/8%20A%20monocular%20vision%20based%20method%20for%20measuring%20pose%20of%20the%20warehouse%20robot%20and%20rebuilding%20contour%20of%20the%20dome%20.pdf' onmouseover=LMTextBrOver('Text7',9) onmousedown=LMTextBrDown('Text7',9) onmouseup=LMTextBrUp('Text7',9) onmouseout=LMTextBrOut('Text7',9) STYLE='cursor:pointer'><font face="Times New Roman" color="#0000ff" size="4"><span style=" font-size:14pt"><u>Full PDF</u></span></font></a><font face="Times New Roman"><span style=" font-size:12pt">]</span></font></p>  </font>
</DIV>
</div></div></div></div></div></div></div></div></div></div>
</DIV>
<DIV id=Text8 style="visibility:visible;position:absolute;z-index:5;left:13;top:2052;">
<a name=#anchor_Text8></a>
<div class=DropBorder><div><div><div><div><div><div><div><div><div style="visibility:inherit;position:relative;left:6;top:6;width:975;height:1636;">
<DIV id=LMTxtText8 style="visibility:inherit;position:relative;left:15;top:15;width:931;height:1592;overflow:auto;overflowX:hidden;overflowY:auto">
<font face='Arial'>  <div align="justify" style="margin-left:26mm; margin-right:0mm; text-indent:-26mm; margin-top:0.00mm; margin-bottom:0.00mm;"><font face="Times New Roman" size="4"><span style=" font-size:14pt"><b>Papers Where I am a co-author</b> (Because of&nbsp; My Engineering Contribution)</span></font></div>  <ol style="margin-top: 0mm; margin-bottom: 0mm; ">  <li style="margin-left: 1pt; margin-right: 0pt; padding-left: 0pt; font-family: Times New Roman;  font-size: 14pt;  color: #010101;  ">  <p align="justify"><font face="Times New Roman" size="4"><span style=" font-size:14pt; font-family:Times New Roman; color:#010101; font-weight:Normal; font-style:Normal; font-decoration:Normal">Sun F, Yu J, <b>Zhao P,</b> et al. Tracking control for a biomimetic robotic fish guided by active vision. <i>International   Journal of Robotics and Automation</i>, 2016, 31(2): 137-145. (SCI) </span></font></p>  </li>  </ol>  <p align="justify" style="margin-left:5mm; margin-right:0mm; text-indent:0mm; margin-top:0.00mm; margin-bottom:0.00mm;"><font face="Times New Roman" size="4"><span style=" font-size:14pt">&nbsp;&nbsp; </span></font><font face="Times New Roman"><span style=" font-size:12pt"><b>Abstra</b>ct: This paper is concerned with control issue   of active vision guided tracking for an agile robotic fish. A control method for guaranteeing   the stability of the swinging head is proposed, which aims at steady image data acquisition. Then, a control framework with the properties of multiple   stages is presented. The artificial landmark-based visual positioning and directional control implemented as a fuzzy logic controller are combined in   this framework. Furthermore, reasonable control strategies are put forward to balance the kinematic performance and the tracking accuracy. Finally,   tracking tests have been conducted on the autonomous robotic fish merely guided by embedded vision. The experimental results indicate the   feasibility and reliability of the proposed methods. [</span></font><A href='https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/CO1%20Tracking%20Control%20for%20A%20Biomimetic%20Robotic%20Fish%20Guided%20by%20Active%20Vision.pdf' onmouseover=LMTextBrOver('Text8',10) onmousedown=LMTextBrDown('Text8',10) onmouseup=LMTextBrUp('Text8',10) onmouseout=LMTextBrOut('Text8',10) STYLE='cursor:pointer'><font face="Times New Roman" color="#0000ff" size="4"><span style=" font-size:14pt"><u>Full PDF</u></span></font></a><font face="Times New Roman"><span style=" font-size:12pt">]</span></font></p>  <p align="justify" style="margin-left:5mm; margin-right:0mm; text-indent:0mm; margin-top:0.00mm; margin-bottom:0.00mm;">&nbsp;</p>  <ol start="2" style="margin-top: 0mm; margin-bottom: 0mm; ">  <li style="margin-left: 1pt; margin-right: 0pt; padding-left: 0pt; font-family: Times New Roman;  font-size: 14pt;  color: #010101;  ">  <p align="justify"><font face="Times New Roman" size="4"><span style=" font-size:14pt; font-family:Times New Roman; color:#010101; font-weight:Normal; font-style:Normal; font-decoration:Normal">Lingyi Xu, Zhiqiang Cao, <b>Peng Zhao</b>, Chao Zhou. A New Monocular Vision Measurement Method to Estimate 3D   Positions of Objects on Floor. <i>International Journal of Automation and Computing</i>, 2017, DOI: 10.1007/s11633-  016-1047-6</span></font></p>  </li>  </ol>  <p align="justify" style="margin-left:5mm; margin-right:0mm; text-indent:0mm; margin-top:0.00mm; margin-bottom:0.00mm;"><font face="Times New Roman" size="4"><span style=" font-size:14pt">&nbsp;&nbsp; </span></font><font face="Times New Roman"><span style=" font-size:12pt"><b>Abstra</b>ct: A new visual measurement method is proposed   to estimate three-dimensional (3D) position of the object on the floor based on a single   camera. The camera fixed on a robot is in an inclined position with respect to the floor. A measurement model with the camera_s extrinsic parameters   such as the height and pitch angle is described. Single image of a chessboard pattern placed on the floor is enough to calibrate the camera_s extrinsic   parameters after the camera_s intrinsic parameters are calibrated. Then the position of object on the floor can be computed with the measurement   model. Furthermore, the height of object can be calculated with the paired-points in the vertical line sharing the same position on the floor. Compared   to the conventional method used to estimate the positions on the plane, this method can obtain the 3D positions. The indoor experiment testifies the   accuracy and validity of the proposed method. [</span></font><A href='https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/CO2%20A%20New%20Monocular%20Vision%20Measurement%20Method%20to%20Estimate%203D%20Positions%20of%20Objects%20on%20Floor.pdf' onmouseover=LMTextBrOver('Text8',11) onmousedown=LMTextBrDown('Text8',11) onmouseup=LMTextBrUp('Text8',11) onmouseout=LMTextBrOut('Text8',11) STYLE='cursor:pointer'><font face="Times New Roman" color="#0000ff" size="4"><span style=" font-size:14pt"><u>Full PDF</u></span></font></a><font face="Times New Roman"><span style=" font-size:12pt">]</span></font></p>  <p align="justify" style="margin-left:5mm; margin-right:0mm; text-indent:0mm; margin-top:0.00mm; margin-bottom:0.00mm;">&nbsp;</p>  <ol start="3" style="margin-top: 0mm; margin-bottom: 0mm; ">  <li style="margin-left: 1pt; margin-right: 0pt; padding-left: 0pt; font-family: Times New Roman;  font-size: 14pt;  color: #010101;  ">  <p align="justify"><font face="Times New Roman" size="4"><span style=" font-size:14pt; font-family:Times New Roman; color:#010101; font-weight:Normal; font-style:Normal; font-decoration:Normal">Jile Jiao, Zhiqiang Cao, <b>Peng Zhao</b>, Xilong Liu and Min Tan</span></font><font face="Calibri" size="4"><span style=" font-size:14pt">C:and   SettingsDocumentsCreator</span></font><font face="Times New Roman" size="4"><span style=" font-size:14pt"> Bezier Curve Based   Path Planning for A Mobile Manipulator in Unknown Environments. <i>IEEE International Conference on Robotics   and Biomimetics</i>, 1864-1868, Shenzhen, 2013.</span></font></p>  </li>  </ol>  <p align="justify" style="margin-left:5mm; margin-right:0mm; text-indent:0mm; margin-top:0.00mm; margin-bottom:0.00mm;"><font face="Times New Roman" size="4"><span style=" font-size:14pt">&nbsp;&nbsp; </span></font><font face="Times New Roman"><span style=" font-size:12pt"><b>Abstra</b>ct: This paper presents a collision-free path   planning approach based on Bezier curve for a mobile manipulator with the endpoints restricted   by the manipulator. Based on these candidate endpoints and the initial posture of mobile manipulator, a series of feasible Bezier paths are obtained   with the constraints from velocity, acceleration and environment.And then the optimal collision-free path is determined according to the related   information of the path as well as obstacles. The mobile manipulator has the ability to adapt to the environment and the optimal path will be updated   once the new detected obstacles block this path. The path planning approach is verified by simulations. [</span></font><A href='https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/CO3%20Bezier%20Curve%20Based%20Path%20Planning%20for%20A%20Mobile%20Manipulator%20in%20Unknown%20Environments.pdf' onmouseover=LMTextBrOver('Text8',12) onmousedown=LMTextBrDown('Text8',12) onmouseup=LMTextBrUp('Text8',12) onmouseout=LMTextBrOut('Text8',12) STYLE='cursor:pointer'><font face="Times New Roman" color="#0000ff" size="4"><span style=" font-size:14pt"><u>Full PDF</u></span></font></a><font face="Times New Roman"><span style=" font-size:12pt">]</span></font></p>  <p align="justify" style="margin-left:5mm; margin-right:0mm; text-indent:0mm; margin-top:0.00mm; margin-bottom:0.00mm;">&nbsp;</p>  <ol start="4" style="margin-top: 0mm; margin-bottom: 0mm; ">  <li style="margin-left: 1pt; margin-right: 0pt; padding-left: 0pt; font-family: Times New Roman;  font-size: 14pt;  color: #010101;  ">  <p align="justify"><font face="Times New Roman" size="4"><span style=" font-size:14pt; font-family:Times New Roman; color:#010101; font-weight:Normal; font-style:Normal; font-decoration:Normal">Jile Jiao, Zhiqiang Cao, <b>Peng Zhao</b>, Xilong Liu and Min Tan</span></font><font face="Calibri" size="4"><span style=" font-size:14pt">C:and   SettingsDocumentsCreator</span></font><font face="Times New Roman" size="4"><span style=" font-size:14pt"> Autonomous Grasp   of the Embedded Mobile Manipulator with an Eye-in-hand Camera. <i>IEEE International Conference on Networking,   Sensing and Control</i>, Miami, 2014, 267-272</span></font><font face="Calibri" size="4"><span style=" font-size:14pt">C:and SettingsDocumentsCreator</span></font><font face="Times New Roman" size="4"><span style=" font-size:14pt"> (EI)</span></font></p>  </li>  </ol>  <p align="justify" style="margin-left:5mm; margin-right:0mm; text-indent:0mm; margin-top:0.00mm; margin-bottom:0.00mm;"><font face="Times New Roman" size="4"><span style=" font-size:14pt">&nbsp;&nbsp; </span></font><font face="Times New Roman"><span style=" font-size:12pt"><b>Abstra</b>ct: This paper proposes an autonomous grasp method   for the embedded mobile manipulator with an eye-in-hand CMOS camera. A three-  stage scheme including object searching, approaching and grasping operation is adopted. With the help of visual information, the Bezier curve based   approaching as well as vision-based approaching adjustment is applied, where an optimal Bezier path is obtained based on the evaluation of its length   and curvature with constraints from the velocity, tangential acceleration and the minimum turning radius. When the mobile manipulator thinks that the   object is within its grasping range, it executes the grasping operation according to image information and inverse kinematics. During the move-tograsp   process, the posture of the manipulator is adjusted in real time to endeavor to make the object be targeted. The validity of the proposed method is   verifed by experiments. [</span></font><A href='https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/CO4%20Autonomous%20Grasp%20of%20the%20Embedded%20Mobile%20Manipulator%20with%20an%20Eye-in-hand%20Camera.pdf' onmouseover=LMTextBrOver('Text8',13) onmousedown=LMTextBrDown('Text8',13) onmouseup=LMTextBrUp('Text8',13) onmouseout=LMTextBrOut('Text8',13) STYLE='cursor:pointer'><font face="Times New Roman" color="#0000ff" size="4"><span style=" font-size:14pt"><u>Full PDF</u></span></font></a><font face="Times New Roman"><span style=" font-size:12pt">]</span></font></p>  <p align="justify" style="margin-left:5mm; margin-right:0mm; text-indent:0mm; margin-top:0.00mm; margin-bottom:0.00mm;">&nbsp;</p>  <ol start="5" style="margin-top: 0mm; margin-bottom: 0mm; ">  <li style="margin-left: 1pt; margin-right: 0pt; padding-left: 0pt; font-family: Times New Roman;  font-size: 14pt;  color: #010101;  ">  <p align="justify"><font face="Times New Roman" size="4"><span style=" font-size:14pt; font-family:Times New Roman; color:#010101; font-weight:Normal; font-style:Normal; font-decoration:Normal">Jile Jiao, Zhiqiang Cao, <b>Peng</b> <b>Zhao </b>and Min Tan. An object grasping method based on fuzzy approaching for a   mobile manipulator. <i>Journal of Huazhong University of Science and Technology </i>(<i>Natural Science Edition</i>). 2013,   41(SI): 47-50. (EI) (In Chinese)</span></font></p>  </li>  </ol>  <p align="justify" style="margin-left:5mm; margin-right:0mm; text-indent:0mm; margin-top:0.00mm; margin-bottom:0.00mm;"><font face="Times New Roman" size="4"><span style=" font-size:14pt">&nbsp;&nbsp; </span></font><font face="Times New Roman"><span style=" font-size:12pt"><b>Abstra</b>ct: An object grasping method based on fuzzy approaching   for a mobile manipulator with an Eye-in-Hand CMOS(complementary metal-  oxide-semiconductor transistor)camera was proposed. The approaching guidance identifier with double cross was recognized by the mobile   manipulator, and the angle between the line from mobile platform to the center of the identifier and its heading direction were served as the inputs of   fuzzy controller. A double input and single output fuzzy controller was designed to regulate the direction of the mobile platform for smooth   approaching. When the object (a red cylinder with double black lines) was in the workspace of manipulator, the mobile platform stops and the object   was grasped by the manipulator with its joint angles solved based on inverse kinematics. Experiments results show the validity of the proposed   approach. [</span></font><A href='https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/CO5%20An%20object%20grasping%20method%20based%20on%20fuzzy%20approaching%20for%20a%20mobile%20manipulator.pdf' onmouseover=LMTextBrOver('Text8',14) onmousedown=LMTextBrDown('Text8',14) onmouseup=LMTextBrUp('Text8',14) onmouseout=LMTextBrOut('Text8',14) STYLE='cursor:pointer'><font face="Times New Roman" color="#0000ff" size="4"><span style=" font-size:14pt"><u>Full PDF</u></span></font></a><font face="Times New Roman"><span style=" font-size:12pt">]</span></font></p>  <p align="justify" style="margin-left:5mm; margin-right:0mm; text-indent:0mm; margin-top:0.00mm; margin-bottom:0.00mm;">&nbsp;</p>  <ol start="6" style="margin-top: 0mm; margin-bottom: 0mm; ">  <li style="margin-left: 1pt; margin-right: 0pt; padding-left: 0pt; font-family: Times New Roman;  font-size: 14pt;  color: #010101;  ">  <p align="justify"><font face="Times New Roman" size="4"><span style=" font-size:14pt; font-family:Times New Roman; color:#010101; font-weight:Normal; font-style:Normal; font-decoration:Normal">Lingyi Xu, Zhiqiang Cao, <b>Peng Zhao</b>, Yixin Yin</span></font><font face="Calibri" size="4"><span style=" font-size:14pt">.</span></font><font   face="Times New Roman" size="4"><span style=" font-size:14pt"> The Identifier-based Relative Position Estimation for Leader-  follower Robotic System, <i>IEEE International Conference on Mechantronics and Automation</i>, 1691-1695, Tianjin,   2014. (EI)</span></font></p>  </li>  </ol>  <p align="justify" style="margin-left:5mm; margin-right:0mm; text-indent:0mm; margin-top:0.00mm; margin-bottom:0.00mm;"><font face="Times New Roman" size="4"><span style=" font-size:14pt">&nbsp;&nbsp;</span></font><font face="Times New Roman"><span style=" font-size:12pt"> <b>Abstra</b>ct:A monocular vision measurement approach is   presented for leader-follower robotic system to estimate the position of the leader robot   relative to the follower robot. The color identifier with green and red blocks is attached on the back of the leader robot, and it may be captured by   the camera mounted on the follower robot. A coarse-to-fine searching method is given to extract the center point of the identifier. The parameters of   the camera with the combination of the intrinsic and extrinsic ones are calibrated via least square method with given relative positions and the   corresponding image coordinates of the identifier’s center. The parameters are further optimized with Levenberg-Marquardt method. Then the   position of the leader robot relative to the follower robot can be estimated only with single feature point. The experimental results verify the validity of   the given approach. [</span></font><A href='https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/CO6%20The%20Identifier-based%20Relative%20Position%20Estimation%20for%20Leader-follower%20Robotic%20System.pdf' onmouseover=LMTextBrOver('Text8',15) onmousedown=LMTextBrDown('Text8',15) onmouseup=LMTextBrUp('Text8',15) onmouseout=LMTextBrOut('Text8',15) STYLE='cursor:pointer'><font face="Times New Roman" color="#0000ff" size="4"><span style=" font-size:14pt"><u>Full PDF</u></span></font></a><font face="Times New Roman"><span style=" font-size:12pt">]</span></font></p>  <p align="justify" style="margin-left:5mm; margin-right:0mm; text-indent:0mm; margin-top:0.00mm; margin-bottom:0.00mm;">&nbsp;</p>  <ol start="7" style="margin-top: 0mm; margin-bottom: 0mm; ">  <li style="margin-left: 1pt; margin-right: 0pt; padding-left: 0pt; font-family: Times New Roman;  font-size: 14pt;  color: #010101;  ">  <p align="justify"><font face="Times New Roman" size="4"><span style=" font-size:14pt; font-family:Times New Roman; color:#010101; font-weight:Normal; font-style:Normal; font-decoration:Normal">Wenbo Yuan, Zhiqiang Cao, <b>Peng Zhao</b>, Min Tan, Yuequan Yang. An Object Recognition Approach based on   Structural Feature for Cluttered Indoor Scene. <i>IEEE International Conference on Networking, Sensing and   Control</i>, Miami, FL, USA, April 7-9, 2014, 92-95. (EI)</span></font></p>  </li>  </ol>  <p align="justify" style="margin-left:5mm; margin-right:0mm; text-indent:0mm; margin-top:0.00mm; margin-bottom:0.00mm;"><font face="Times New Roman" size="4"><span style=" font-size:14pt">&nbsp;&nbsp; </span></font><font face="Times New Roman"><span style=" font-size:12pt"><b>Abstra</b>ct: In this paper, aiming at the indoor scene   under monitoring by visual sensor network (VSN), an object recognition approach based on   structural feature is presented. Firstly, we regard the output of existing line segment detector LSD with proper parameters as the preliminary   extraction result and it still will be further restored and split. Then, we give an inference model based on structural features of object including line   segment ontology characteristics and relative relationship between the line segments. Finally, the objects are recognized with position information   through inference. The effectiveness of the approach is verifed, and the results show that our approach does not rely on segmentation and has   robustness on partial defect and structural deformation to some extent. [</span></font><A href='https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/CO7%20An%20object%20recognition%20approach%20based%20on%20structural%20feature%20for%20cluttered%20indoor%20scene.pdf' onmouseover=LMTextBrOver('Text8',16) onmousedown=LMTextBrDown('Text8',16) onmouseup=LMTextBrUp('Text8',16) onmouseout=LMTextBrOut('Text8',16) STYLE='cursor:pointer'><font face="Times New Roman" color="#0000ff" size="4"><span style=" font-size:14pt"><u>Full PDF</u></span></font></a><font face="Times New Roman"><span style=" font-size:12pt">]</span></font></p>  </font>
</DIV>
</div></div></div></div></div></div></div></div></div></div>
</DIV>
<DIV id=Text9 style="visibility:visible;position:absolute;z-index:6;left:17;top:1972;">
<a name=#anchor_Text9></a>
<div class=DropBorder><div><div><div><div><div><div><div><div><div style="visibility:inherit;position:relative;left:6;top:6;width:161;height:56;">
<DIV id=LMTxtText9 style="visibility:inherit;position:relative;left:8;top:8;width:134;height:26;overflow:auto;overflowX:hidden;overflowY:auto">
<font face='Arial'>  <div align="left"><A href='https://bonself.github.io/My-Basic-info' onmouseover=LMTextBrOver('Text9',1) onmousedown=LMTextBrDown('Text9',1) onmouseup=LMTextBrUp('Text9',1) onmouseout=LMTextBrOut('Text9',1) STYLE='cursor:pointer'><font face="Arial" color="#0000ff" size="5"><span style=" font-size:18pt"><u>Basic Info</u></span></font></a></div>  </font>
</DIV>
</div></div></div></div></div></div></div></div></div></div>
</DIV>
<DIV id=Text10 style="visibility:visible;position:absolute;z-index:7;left:374;top:1974;">
<a name=#anchor_Text10></a>
<div class=DropBorder><div><div><div><div><div><div><div><div><div style="visibility:inherit;position:relative;left:6;top:6;width:167;height:56;">
<DIV id=LMTxtText10 style="visibility:inherit;position:relative;left:8;top:8;width:140;height:26;">
<font face='Arial'>  <div align="left"><A href='https://bonself.github.io/My-rewards' onmouseover=LMTextBrOver('Text10',1) onmousedown=LMTextBrDown('Text10',1) onmouseup=LMTextBrUp('Text10',1) onmouseout=LMTextBrOut('Text10',1) STYLE='cursor:pointer'><font face="Arial" color="#0000ff" size="4"><span style=" font-size:16pt"><u>My </u></span></font><font   face="Times New Roman" color="#0000ff" size="4"><span style=" font-size:16pt"><u>Prototypes</u></span></font></a></div>  </font>
</DIV>
</div></div></div></div></div></div></div></div></div></div>
</DIV>
<DIV id=Text11 style="visibility:visible;position:absolute;z-index:8;left:551;top:1974;">
<a name=#anchor_Text11></a>
<div class=DropBorder><div><div><div><div><div><div><div><div><div style="visibility:inherit;position:relative;left:6;top:6;width:171;height:56;">
<DIV id=LMTxtText11 style="visibility:inherit;position:relative;left:8;top:8;width:144;height:26;">
<font face='Arial'>  <div align="left"><A href='https://bonself.github.io/My-rewards' onmouseover=LMTextBrOver('Text11',1) onmousedown=LMTextBrDown('Text11',1) onmouseup=LMTextBrUp('Text11',1) onmouseout=LMTextBrOut('Text11',1) STYLE='cursor:pointer'><font face="Arial" color="#0000ff" size="4"><span style=" font-size:16pt"><u>My Rewards</u></span></font></a></div>  </font>
</DIV>
</div></div></div></div></div></div></div></div></div></div>
</DIV>
<DIV id=Text12 style="visibility:visible;position:absolute;z-index:9;left:192;top:1973;">
<a name=#anchor_Text12></a>
<div class=DropBorder><div><div><div><div><div><div><div><div><div style="visibility:inherit;position:relative;left:6;top:6;width:173;height:56;">
<DIV id=LMTxtText12 style="visibility:inherit;position:relative;left:8;top:8;width:146;height:26;">
<font face='Arial'>  <div align="left"><A href='https://bonself.github.io/My-papers' onmouseover=LMTextBrOver('Text12',1) onmousedown=LMTextBrDown('Text12',1) onmouseup=LMTextBrUp('Text12',1) onmouseout=LMTextBrOut('Text12',1) STYLE='cursor:pointer'><font face="Arial" color="#0000ff" size="4"><span style=" font-size:16pt"><u>My Papers</u></span></font></a></div>  </font>
</DIV>
</div></div></div></div></div></div></div></div></div></div>
</DIV>
<DIV id=Text13 style="visibility:visible;position:absolute;z-index:10;left:148;top:3705;">
<a name=#anchor_Text13></a>
<div class=DropBorder><div><div><div><div><div><div><div><div><div style="visibility:inherit;position:relative;left:6;top:6;width:161;height:56;">
<DIV id=LMTxtText13 style="visibility:inherit;position:relative;left:8;top:8;width:134;height:26;overflow:auto;overflowX:hidden;overflowY:auto">
<font face='Arial'>  <div align="left"><A href='https://bonself.github.io/My-Basic-info' onmouseover=LMTextBrOver('Text13',1) onmousedown=LMTextBrDown('Text13',1) onmouseup=LMTextBrUp('Text13',1) onmouseout=LMTextBrOut('Text13',1) STYLE='cursor:pointer'><font face="Arial" color="#0000ff" size="5"><span style=" font-size:18pt"><u>Basic Info</u></span></font></a></div>  </font>
</DIV>
</div></div></div></div></div></div></div></div></div></div>
</DIV>
<DIV id=Text14 style="visibility:visible;position:absolute;z-index:11;left:505;top:3707;">
<a name=#anchor_Text14></a>
<div class=DropBorder><div><div><div><div><div><div><div><div><div style="visibility:inherit;position:relative;left:6;top:6;width:167;height:56;">
<DIV id=LMTxtText14 style="visibility:inherit;position:relative;left:8;top:8;width:140;height:26;">
<font face='Arial'>  <div align="left"><A href='https://bonself.github.io/My-rewards' onmouseover=LMTextBrOver('Text14',1) onmousedown=LMTextBrDown('Text14',1) onmouseup=LMTextBrUp('Text14',1) onmouseout=LMTextBrOut('Text14',1) STYLE='cursor:pointer'><font face="Arial" color="#0000ff" size="4"><span style=" font-size:16pt"><u>My </u></span></font><font   face="Times New Roman" color="#0000ff" size="4"><span style=" font-size:16pt"><u>Prototypes</u></span></font></a></div>  </font>
</DIV>
</div></div></div></div></div></div></div></div></div></div>
</DIV>
<DIV id=Text15 style="visibility:visible;position:absolute;z-index:12;left:682;top:3707;">
<a name=#anchor_Text15></a>
<div class=DropBorder><div><div><div><div><div><div><div><div><div style="visibility:inherit;position:relative;left:6;top:6;width:171;height:56;">
<DIV id=LMTxtText15 style="visibility:inherit;position:relative;left:8;top:8;width:144;height:26;">
<font face='Arial'>  <div align="left"><A href='https://bonself.github.io/My-rewards' onmouseover=LMTextBrOver('Text15',1) onmousedown=LMTextBrDown('Text15',1) onmouseup=LMTextBrUp('Text15',1) onmouseout=LMTextBrOut('Text15',1) STYLE='cursor:pointer'><font face="Arial" color="#0000ff" size="4"><span style=" font-size:16pt"><u>My Rewards</u></span></font></a></div>  </font>
</DIV>
</div></div></div></div></div></div></div></div></div></div>
</DIV>
<DIV id=Text16 style="visibility:visible;position:absolute;z-index:13;left:323;top:3706;">
<a name=#anchor_Text16></a>
<div class=DropBorder><div><div><div><div><div><div><div><div><div style="visibility:inherit;position:relative;left:6;top:6;width:173;height:56;">
<DIV id=LMTxtText16 style="visibility:inherit;position:relative;left:8;top:8;width:146;height:26;">
<font face='Arial'>  <div align="left"><A href='https://bonself.github.io/My-papers' onmouseover=LMTextBrOver('Text16',1) onmousedown=LMTextBrDown('Text16',1) onmouseup=LMTextBrUp('Text16',1) onmouseout=LMTextBrOut('Text16',1) STYLE='cursor:pointer'><font face="Arial" color="#0000ff" size="4"><span style=" font-size:16pt"><u>My Papers</u></span></font></a></div>  </font>
</DIV>
</div></div></div></div></div></div></div></div></div></div>
</DIV>

<script type="text/javascript">
//LMSOFT Web Creator Pro, Version:4.0.0.4 service pack 1

//LMSOFT Kernel 70 service pack 1

var LMObjects = new Array();
var pub_home = "./index.html"
var objindex=0;
var Stretch=2;
var Position=5;
var ScaleW=1.000000;
var ScaleH=1.000000;
var fontbase=96.;
var isdisplay=false;
//---------------------------------------------------------------------------------------------
try {
if(isValideBrowser(4.00,4.00)) {
InitResources();
//---------------------------------------------------------------------------------------------
LMObjects[objindex++] = LMPage("Page",null,null,null,0);
branchlist = new Array();
LMObjects[objindex++] = LMText("Text1",1,0,null,0,null,branchlist,null,null,15,15,15,15);
branchlist = new Array();
LMObjects[objindex++] = LMText("Text3",1,0,null,0,null,branchlist,null,null,15,15,15,15);
branchlist = new Array();
branchlist[0] = null;
branchlist[1] = new LMBranchEx("2","https://github.com/bonself/Go-aboard/raw/master/papers/1%20A%20coordinated%20docking%20approach%20based%20on%20embedded%20vision.pdf",null,0.0,null,"NULL",0,1,1,1,1,1,0,640,480,"NULL");
branchlist[2] = new LMBranchEx("3","https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/2%20Embedded%20Vision%20Based%20Docking%20Approach%20for%20The%20Child%20Robot.pdf",null,0.0,null,"NULL",0,1,1,1,1,1,0,640,480,"NULL");
branchlist[3] = new LMBranchEx("4","https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/3%20A%20Docking%20Approach%20for%20Child%20Robot%20Based%20on%20Vision%20Guiding%20By%20Mother%20Robot.pdf",null,0.0,null,"NULL",0,1,1,1,1,1,0,640,480,"NULL");
branchlist[4] = new LMBranchEx("5","https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/4%20The%20Design%20of%20a%20Mother%20Robot%20for%20Marsupial%20Robotic%20System.pdf",null,0.0,null,"NULL",0,1,1,1,1,1,0,640,480,"NULL");
branchlist[5] = new LMBranchEx("6","https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/5%20A%20Visual%20Servoing%20Docking%20Approach%20for%20Marsupial%20Robotic%20System.pdf",null,0.0,null,"NULL",0,1,1,1,1,1,0,640,480,"NULL");
branchlist[6] = new LMBranchEx("7","https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/6%20The%20Goalkeeper%20Strategy%20of%20RoboCup%20MSL%20Based%20on%20Dual%20Image%20Source..pdf",null,0.0,null,"NULL",0,1,1,1,1,1,0,640,480,"NULL");
branchlist[7] = new LMBranchEx("8","https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/7%20The%20Design%20of%20a%20Indoor%20Guide%20Robot%20Based%20on%20Embedded%20Control%20System(final%20Paper).pdf",null,0.0,null,"NULL",0,1,1,1,1,1,0,640,480,"NULL");
branchlist[8] = new LMBranchEx("9","https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/8%20A%20monocular%20vision%20based%20method%20for%20measuring%20pose%20of%20the%20warehouse%20robot%20and%20rebuilding%20contour%20of%20the%20dome%20.pdf",null,0.0,null,"NULL",0,1,1,1,1,1,0,640,480,"NULL");
LMObjects[objindex++] = LMText("Text7",1,0,null,0,null,branchlist,null,null,15,15,15,15);
branchlist = new Array();
branchlist[0] = new LMBranchEx("10","https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/CO1%20Tracking%20Control%20for%20A%20Biomimetic%20Robotic%20Fish%20Guided%20by%20Active%20Vision.pdf",null,0.0,null,"NULL",0,1,1,1,1,1,0,640,480,"NULL");
branchlist[1] = new LMBranchEx("11","https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/CO2%20A%20New%20Monocular%20Vision%20Measurement%20Method%20to%20Estimate%203D%20Positions%20of%20Objects%20on%20Floor.pdf",null,0.0,null,"NULL",0,1,1,1,1,1,0,640,480,"NULL");
branchlist[2] = new LMBranchEx("12","https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/CO3%20Bezier%20Curve%20Based%20Path%20Planning%20for%20A%20Mobile%20Manipulator%20in%20Unknown%20Environments.pdf",null,0.0,null,"NULL",0,1,1,1,1,1,0,640,480,"NULL");
branchlist[3] = new LMBranchEx("13","https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/CO4%20Autonomous%20Grasp%20of%20the%20Embedded%20Mobile%20Manipulator%20with%20an%20Eye-in-hand%20Camera.pdf",null,0.0,null,"NULL",0,1,1,1,1,1,0,640,480,"NULL");
branchlist[4] = new LMBranchEx("14","https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/CO5%20An%20object%20grasping%20method%20based%20on%20fuzzy%20approaching%20for%20a%20mobile%20manipulator.pdf",null,0.0,null,"NULL",0,1,1,1,1,1,0,640,480,"NULL");
branchlist[5] = new LMBranchEx("15","https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/CO6%20The%20Identifier-based%20Relative%20Position%20Estimation%20for%20Leader-follower%20Robotic%20System.pdf",null,0.0,null,"NULL",0,1,1,1,1,1,0,640,480,"NULL");
branchlist[6] = new LMBranchEx("16","https://raw.githubusercontent.com/bonself/Go-aboard/master/papers/CO7%20An%20object%20recognition%20approach%20based%20on%20structural%20feature%20for%20cluttered%20indoor%20scene.pdf",null,0.0,null,"NULL",0,1,1,1,1,1,0,640,480,"NULL");
LMObjects[objindex++] = LMText("Text8",1,0,null,0,null,branchlist,null,null,15,15,15,15);
branchlist = new Array();
branchlist[0] = new LMBranchEx("1","https://bonself.github.io/My-Basic-info",null,0.0,null,"NULL",0,1,1,1,1,1,0,640,480,"NULL");
LMObjects[objindex++] = LMText("Text9",1,0,null,0,null,branchlist,null,null,8,8,5,8);
branchlist = new Array();
branchlist[0] = new LMBranchEx("1","https://bonself.github.io/My-rewards",null,0.0,null,"NULL",0,1,1,1,1,1,0,640,480,"NULL");
LMObjects[objindex++] = LMText("Text10",1,0,null,0,null,branchlist,null,null,8,8,5,8);
branchlist = new Array();
branchlist[0] = new LMBranchEx("1","https://bonself.github.io/My-rewards",null,0.0,null,"NULL",0,1,1,1,1,1,0,640,480,"NULL");
LMObjects[objindex++] = LMText("Text11",1,0,null,0,null,branchlist,null,null,8,8,5,8);
branchlist = new Array();
branchlist[0] = new LMBranchEx("1","https://bonself.github.io/My-papers",null,0.0,null,"NULL",0,1,1,1,1,1,0,640,480,"NULL");
LMObjects[objindex++] = LMText("Text12",1,0,null,0,null,branchlist,null,null,8,8,5,8);
branchlist = new Array();
branchlist[0] = new LMBranchEx("1","https://bonself.github.io/My-Basic-info",null,0.0,null,"NULL",0,1,1,1,1,1,0,640,480,"NULL");
LMObjects[objindex++] = LMText("Text13",1,0,null,0,null,branchlist,null,null,8,8,5,8);
branchlist = new Array();
branchlist[0] = new LMBranchEx("1","https://bonself.github.io/My-rewards",null,0.0,null,"NULL",0,1,1,1,1,1,0,640,480,"NULL");
LMObjects[objindex++] = LMText("Text14",1,0,null,0,null,branchlist,null,null,8,8,5,8);
branchlist = new Array();
branchlist[0] = new LMBranchEx("1","https://bonself.github.io/My-rewards",null,0.0,null,"NULL",0,1,1,1,1,1,0,640,480,"NULL");
LMObjects[objindex++] = LMText("Text15",1,0,null,0,null,branchlist,null,null,8,8,5,8);
branchlist = new Array();
branchlist[0] = new LMBranchEx("1","https://bonself.github.io/My-papers",null,0.0,null,"NULL",0,1,1,1,1,1,0,640,480,"NULL");
LMObjects[objindex++] = LMText("Text16",1,0,null,0,null,branchlist,null,null,8,8,5,8);
//---------------------------------------------------------------------------------------------
}
}catch(e) {
alert(e.message);
}
SetBaseColor(0x3f0,0x3f9,0x87);
if(isdisplay==true) GetDisplayInfo("","",0,"","./");
else LMObjectAnimate(Stretch,Position,ScaleW,ScaleH);
</script><noscript><br></noscript>
</DIV>

</body>
</html>
